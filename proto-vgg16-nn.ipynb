{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training videos\n",
    "import cv2\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "import subprocess\n",
    "\n",
    "NUM_FRAMES = 100\n",
    "TAKES_PER = 2\n",
    "CLASSES = ['SAFE', 'DANGER']\n",
    "NEG_IDX = 0\n",
    "POS_IDX = 1\n",
    "HIDDEN_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get ready to act: SAFE\n",
      "Recording started\n",
      "Recording stopped\n",
      "Get ready to act: DANGER\n",
      "Recording started\n",
      "Recording stopped\n",
      "Get ready to act: SAFE\n",
      "Recording started\n",
      "Recording stopped\n",
      "Get ready to act: DANGER\n",
      "Recording started\n",
      "Recording stopped\n"
     ]
    }
   ],
   "source": [
    "# Photo studio\n",
    "# Here you can record movies to use as training data\n",
    "# Get ready to act either excited or relaxed!\n",
    "# Videos are stored in data dir\n",
    "def capture(num_frames, path='out.avi', countdown=0):\n",
    "    for i in reversed(range(max(0, countdown))):\n",
    "        i = 'GO!' if i == 0 else '{}  '.format(i)\n",
    "        subprocess.call(['say', str(i)])\n",
    "        sys.stdout.write(\"{}   \\r\".format(i))\n",
    "        sys.stdout.flush()\n",
    "        sleep(1)\n",
    "\n",
    "    # Create a VideoCapture object\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Check if camera opened successfully\n",
    "    if (cap.isOpened() == False): \n",
    "        print(\"Unable to read camera feed\")\n",
    "\n",
    "    # Default resolutions of the frame are obtained.The default resolutions are system dependent.\n",
    "    # We convert the resolutions from float to integer.\n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "\n",
    "    # Define the codec and create VideoWriter object.The output is stored in 'outpy.avi' file.\n",
    "    out = cv2.VideoWriter(path, cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))\n",
    "\n",
    "    print('Recording started')\n",
    "    for i in range(num_frames):\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if ret == True:     \n",
    "            # Write the frame into the file 'output.avi'\n",
    "            out.write(frame)\n",
    "\n",
    "\n",
    "    # When everything done, release the video capture and video write objects\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print('Recording stopped')\n",
    "    \n",
    "for take in range(TAKES_PER):\n",
    "    for cla in CLASSES:\n",
    "        path = 'data/{}{}.avi'.format(cla, take)\n",
    "        print('Get ready to act:', cla)\n",
    "        subprocess.call(['say', 'get ready to act {}'.format(cla)])\n",
    "        capture(NUM_FRAMES, path=path, countdown=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing data/SAFE0.avi\n",
      "(100, 25088)\n",
      "(100, 2)\n",
      "preprocessing data/SAFE1.avi\n",
      "(100, 25088)\n",
      "(100, 2)\n",
      "preprocessing data/DANGER0.avi\n",
      "(100, 25088)\n",
      "(100, 2)\n",
      "preprocessing data/DANGER1.avi\n",
      "(100, 25088)\n",
      "(100, 2)\n",
      "(400, 25088)\n",
      "(400, 2)\n"
     ]
    }
   ],
   "source": [
    "# Create X, y series\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "class VGGFramePreprocessor():\n",
    "    \n",
    "    def __init__(self, vgg_model):\n",
    "        self.vgg_model = vgg_model\n",
    "    \n",
    "    def process(self, frame):\n",
    "        img_data = cv2.resize(frame,(224,224))\n",
    "        img_data = np.expand_dims(img_data, axis=0)\n",
    "        img_data = preprocess_input(img_data)\n",
    "        x = self.vgg_model.predict(img_data).flatten()\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        return x\n",
    "\n",
    "def get_video_frames(video_path):\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    success, frame = vidcap.read()\n",
    "    while success:\n",
    "        yield frame\n",
    "        success,frame = vidcap.read()\n",
    "    vidcap.release()\n",
    "    \n",
    "frame_preprocessor = VGGFramePreprocessor(VGG16(weights='imagenet', include_top=False))\n",
    "\n",
    "# Load movies and transform frames to features\n",
    "movies = []\n",
    "X = []\n",
    "y = []\n",
    "for video_path in glob.glob('data/*.avi'):\n",
    "    print('preprocessing', video_path)\n",
    "    positive = CLASSES[POS_IDX] in video_path\n",
    "    _X = np.concatenate([frame_preprocessor.process(frame) for frame in get_video_frames(video_path)])\n",
    "    _y = np.array(_X.shape[0] * [[int(not positive), int(positive)]])\n",
    "    X.append(_X)\n",
    "    y.append(_y)\n",
    "        \n",
    "X = np.concatenate(X)\n",
    "y = np.concatenate(y)\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display an image\n",
    "img = Image.fromarray(X[0].reshape(49,512))\n",
    "img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 30 samples\n",
      "Epoch 1/5\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 6.8286 - acc: 0.5741 - val_loss: 7.5218 - val_acc: 0.5333\n",
      "Epoch 2/5\n",
      "270/270 [==============================] - 0s 559us/step - loss: 5.0037 - acc: 0.6889 - val_loss: 0.2144 - val_acc: 0.9333\n",
      "Epoch 3/5\n",
      "270/270 [==============================] - 0s 592us/step - loss: 4.7446 - acc: 0.7037 - val_loss: 0.5373 - val_acc: 0.9667\n",
      "Epoch 4/5\n",
      "270/270 [==============================] - 0s 561us/step - loss: 4.1833 - acc: 0.7333 - val_loss: 3.7609 - val_acc: 0.7667\n",
      "Epoch 5/5\n",
      "270/270 [==============================] - 0s 550us/step - loss: 3.3728 - acc: 0.7852 - val_loss: 1.1921e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a6a13aa20>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "HIDDEN_SIZE = 16\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(HIDDEN_SIZE, input_shape=(X.shape[1],)))\n",
    "model.add(Dense(HIDDEN_SIZE))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(CLASSES), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "          \n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=10, epochs=5,\n",
    "          validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_true = [np.argmax(y) for y in y_test]\n",
    "y_pred = [np.argmax(pred) for pred in model.predict(x_test)]\n",
    "score = f1_score(y_true, y_pred)\n",
    "print('F1:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing 0%  conf_neg = 1.00 conf_pos = 0.00   class = SAFE         \r"
     ]
    }
   ],
   "source": [
    "# Infer on live video\n",
    "from math import ceil\n",
    "import subprocess\n",
    "\n",
    "TEST_FRAMES = 200\n",
    "\n",
    "# Initialize camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened() == False): \n",
    "    print(\"Unable to read camera feed\")\n",
    "    test_frames = 0\n",
    "\n",
    "# Start processing video\n",
    "for i in range(TEST_FRAMES):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: continue\n",
    "    x_pred = frame_preprocessor.process(frame)\n",
    "    y_pred = model.predict(x_pred)[0]\n",
    "    conf_negative = y_pred[NEG_IDX]\n",
    "    conf_positive = y_pred[POS_IDX]\n",
    "    cla = CLASSES[np.argmax(y_pred)]\n",
    "    if cla == CLASSES[POS_IDX]:\n",
    "        subprocess.call(['say',  CLASSES[POS_IDX]])\n",
    "    progress = int(100 * (i / TEST_FRAMES))\n",
    "    message = 'testing {}%  conf_neg = {:.02f} conf_pos = {:.02f}   class = {}         \\r'.format(progress, conf_negative, conf_positive, cla)\n",
    "    sys.stdout.write(message)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (p3-ai)",
   "language": "python",
   "name": "p3-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
