{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training videos\n",
    "import cv2\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "import subprocess\n",
    "\n",
    "NUM_FRAMES = 100\n",
    "TAKES_PER = 2\n",
    "CLASSES = ['SAFE', 'DANGER']\n",
    "NEG_IDX = 0\n",
    "POS_IDX = 1\n",
    "HIDDEN_SIZE = 256\n",
    "\n",
    "MODEL_PATH='model.h5'\n",
    "TRAIN_MODEL = True\n",
    "EPOCHS = 10\n",
    "HIDDEN_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get ready to act: SAFE\n",
      "Recording started\n",
      "Recording stopped\n",
      "Get ready to act: DANGER\n",
      "Recording started\n",
      "Recording stopped\n",
      "Get ready to act: SAFE\n",
      "Recording started\n",
      "Recording stopped\n",
      "Get ready to act: DANGER\n",
      "Recording started\n",
      "Recording stopped\n"
     ]
    }
   ],
   "source": [
    "# Photo studio\n",
    "# Here you can record movies to use as training data\n",
    "# Get ready to act either excited or relaxed!\n",
    "# Videos are stored in data dir\n",
    "def capture(num_frames, path='out.avi', countdown=0):\n",
    "    for i in reversed(range(max(0, countdown))):\n",
    "        i = 'GO!' if i == 0 else '{}  '.format(i)\n",
    "        subprocess.call(['say', str(i)])\n",
    "        sys.stdout.write(\"{}   \\r\".format(i))\n",
    "        sys.stdout.flush()\n",
    "        sleep(1)\n",
    "\n",
    "    # Create a VideoCapture object\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Check if camera opened successfully\n",
    "    if (cap.isOpened() == False): \n",
    "        print(\"Unable to read camera feed\")\n",
    "\n",
    "    # Default resolutions of the frame are obtained.The default resolutions are system dependent.\n",
    "    # We convert the resolutions from float to integer.\n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "\n",
    "    # Define the codec and create VideoWriter object.The output is stored in 'outpy.avi' file.\n",
    "    out = cv2.VideoWriter(path, cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))\n",
    "\n",
    "    print('Recording started')\n",
    "    for i in range(num_frames):\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if ret == True:     \n",
    "            # Write the frame into the file 'output.avi'\n",
    "            out.write(frame)\n",
    "\n",
    "\n",
    "    # When everything done, release the video capture and video write objects\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print('Recording stopped')\n",
    "\n",
    "if TRAIN_MODEL:\n",
    "    for take in range(TAKES_PER):\n",
    "        for cla in CLASSES:\n",
    "            path = 'data/{}{}.avi'.format(cla, take)\n",
    "            print('Get ready to act:', cla)\n",
    "            subprocess.call(['say', 'get ready to act {}'.format(cla)])\n",
    "            capture(NUM_FRAMES, path=path, countdown=3)\n",
    "    subprocess.call(['say', 'Capture complete'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing data/SAFE0.avi\n",
      "preprocessing data/SAFE1.avi\n",
      "preprocessing data/DANGER0.avi\n",
      "preprocessing data/DANGER1.avi\n",
      "(400, 25088)\n",
      "(400, 2)\n"
     ]
    }
   ],
   "source": [
    "# Create X, y series\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "class VGGFramePreprocessor():\n",
    "    \n",
    "    def __init__(self, vgg_model):\n",
    "        self.vgg_model = vgg_model\n",
    "    \n",
    "    def process(self, frame):\n",
    "        img_data = cv2.resize(frame,(224,224))\n",
    "        img_data = np.expand_dims(img_data, axis=0)\n",
    "        img_data = preprocess_input(img_data)\n",
    "        x = self.vgg_model.predict(img_data).flatten()\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        return x\n",
    "\n",
    "def get_video_frames(video_path):\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    success, frame = vidcap.read()\n",
    "    while success:\n",
    "        yield frame\n",
    "        success,frame = vidcap.read()\n",
    "    vidcap.release()\n",
    "\n",
    "\n",
    "frame_preprocessor = VGGFramePreprocessor(VGG16(weights='imagenet', include_top=False))\n",
    "    \n",
    "if TRAIN_MODEL:\n",
    "\n",
    "    # Load movies and transform frames to features\n",
    "    movies = []\n",
    "    X = []\n",
    "    y = []\n",
    "    for video_path in glob.glob('data/*.avi'):\n",
    "        print('preprocessing', video_path)\n",
    "        positive = CLASSES[POS_IDX] in video_path\n",
    "        _X = np.concatenate([frame_preprocessor.process(frame) for frame in get_video_frames(video_path)])\n",
    "        _y = np.array(_X.shape[0] * [[int(not positive), int(positive)]])\n",
    "        X.append(_X)\n",
    "        y.append(_y)\n",
    "\n",
    "    X = np.concatenate(X)\n",
    "    y = np.concatenate(y)\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "if TRAIN_MODEL:\n",
    "    model = Sequential()\n",
    "    model.add(Dense(HIDDEN_SIZE, input_shape=(X.shape[1],)))\n",
    "    model.add(Dense(HIDDEN_SIZE))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(len(CLASSES), activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=10, epochs=EPOCHS,\n",
    "              validation_split=0.1)\n",
    "    model.save(MODEL_PATH)\n",
    "    y_true = [np.argmax(y) for y in y_test]\n",
    "    y_pred = [np.argmax(pred) for pred in model.predict(x_test)]\n",
    "    score = f1_score(y_true, y_pred)\n",
    "    print('F1:', score)    \n",
    "else:\n",
    "    model = load_model(MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing 8%  conf_neg = 0.00 conf_pos = 1.00   class = DANGER         \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ac559b51ce31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mcla\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCLASSES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcla\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mCLASSES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPOS_IDX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'say'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mCLASSES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPOS_IDX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mprogress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mTEST_FRAMES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'testing {}%  conf_neg = {:.02f} conf_pos = {:.02f}   class = {}         \\r'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf_negative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf_positive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p3-ai/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p3-ai/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout, endtime)\u001b[0m\n\u001b[1;32m   1455\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m                             \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# Another thread waited.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m                         \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1458\u001b[0m                         \u001b[0;31m# Check the pid and loop as waitpid has been known to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m                         \u001b[0;31m# return 0 even without WNOHANG in odd situations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p3-ai/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m_try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1402\u001b[0m             \u001b[0;34m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1404\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1405\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mChildProcessError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m                 \u001b[0;31m# This happens if SIGCLD is set to be ignored or waiting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Infer on live video\n",
    "from math import ceil\n",
    "import subprocess\n",
    "\n",
    "TEST_FRAMES = 500\n",
    "\n",
    "# Initialize camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened() == False): \n",
    "    print(\"Unable to read camera feed\")\n",
    "    test_frames = 0\n",
    "\n",
    "# Start processing video\n",
    "for i in range(TEST_FRAMES):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: continue\n",
    "    x_pred = frame_preprocessor.process(frame)\n",
    "    y_pred = model.predict(x_pred)[0]\n",
    "    conf_negative = y_pred[NEG_IDX]\n",
    "    conf_positive = y_pred[POS_IDX]\n",
    "    cla = CLASSES[np.argmax(y_pred)]\n",
    "    if cla == CLASSES[POS_IDX]:\n",
    "        subprocess.call(['say',  CLASSES[POS_IDX]])\n",
    "    progress = int(100 * (i / TEST_FRAMES))\n",
    "    message = 'testing {}%  conf_neg = {:.02f} conf_pos = {:.02f}   class = {}         \\r'.format(progress, conf_negative, conf_positive, cla)\n",
    "    sys.stdout.write(message)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (p3-ai)",
   "language": "python",
   "name": "p3-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
